{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "console.log(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  { label: \"positive\", score: 0.9836677312850952 },\n",
      "  { label: \"neutral\", score: 0.01135887298732996 },\n",
      "  { label: \"negative\", score: 0.004973393864929676 }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const inference = new HfInference(process.env.HUGGING_FACE_API_KEY as string);\n",
    "import dotenv from \"dotenv\";\n",
    "\n",
    "\n",
    "const result = await inference.textClassification({\n",
    "    model: \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    inputs: \"Today is a great day\",\n",
    "});\n",
    "\n",
    "console.log(result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  parsed: { HUGGING_FACE_API_KEY: \u001b[32m\"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\"\u001b[39m }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { HfInference } from \"@huggingface/inference\";\n",
    "import dotenv from \"dotenv\";\n",
    "\n",
    "// Load environment variables from .env file\n",
    "dotenv.config();\n",
    "// Function to generate text using the specified Hugging Face model\n",
    "async function askQuestion(question: string) {\n",
    "    const hf = new HfInference(process.env.HUGGING_FACE_API_KEY as string); // Use the API key from the environment variable\n",
    "\n",
    "    // Use the \"cognitivecomputations/WizardLM-7B-Uncensored\" model for text generation\n",
    "  \n",
    "\n",
    "\n",
    "    try {\n",
    "        const result = await hf.textGeneration({\n",
    "            model: \"Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2-GGUF\",\n",
    "            inputs: question,\n",
    "        });\n",
    "        \n",
    "        console.log(result);\n",
    "    } catch (error) {\n",
    "        console.error(\"Error during inference:\", error);\n",
    "    }\n",
    "}\n",
    "\n",
    "async function main() {\n",
    "    await askQuestion(\"What is the capital of France?\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async function main() {\n",
    "    await askQuestion(\"What is the capital of France?\");\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
